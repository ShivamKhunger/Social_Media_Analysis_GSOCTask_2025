# -*- coding: utf-8 -*-
"""Sentiment & Crisis Risk Classification (NLP & Text Processing).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZT2SsT6Gri71Tb75zOE78v5JDeAPXPWF
"""

#!pip install gensim
#!pip install textblob
import pandas as pd
from textblob import TextBlob
from gensim.models import Word2Vec
import matplotlib.pyplot as plt
import seaborn as sns

path = "reddit_mentalhealth_data.csv"
df = pd.read_csv(path)
df.head()

def sentiment(text):
    polarity = TextBlob(text).sentiment.polarity
    if polarity > 0:
        return "Positive"
    elif polarity < 0:
        return "Negative"
    else:
        return "Neutral"

df["sentiment"] = df["content"].apply(sentiment)
df.head()

sentences = [row.split() for row in df["content"].dropna()]
word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)

highrisk_words = ["suicide", "hopeless", "end", "worthless", "alone", "kill", "pain", "goodbye", "die", "selfharm", "drowning", "tired", "give up", "empty", "pointless"]
moderaterisk_words = ["help", "lost", "struggle", "depressed", "anxiety", "breakdown","overwhelmed", "stressed", "panic", "fear", "crying", "exhausted", "sad", "drained", "numb"]

def risk_classification(text):
    words = text.split()
    if any(word in words for word in highrisk_words):
        return "High Concern"
    elif any(word in words for word in moderaterisk_words):
        return "Moderate Concern"
    else:
        return "Low Concern"

df["risk"] = df["content"].apply(risk_classification)
df.to_csv("reddit_risk_classification.csv", index=False)

plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
sns.countplot(x=df["sentiment"])
plt.title("Distribution of Sentiment")
plt.xlabel("Sentiment")
plt.ylabel("Count")

plt.subplot(1, 2, 2)
sns.countplot(x=df["risk"])
plt.title("Distribution of Risk Levels")
plt.xlabel("Risk Level")
plt.ylabel("Count")

plt.show()

